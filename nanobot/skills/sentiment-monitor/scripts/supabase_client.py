#!/usr/bin/env python3
"""
Supabase Client for Sentiment Monitoring
æä¾›ä¸Supabaseæ•°æ®åº“äº¤äº’çš„æ‰€æœ‰æ–¹æ³•
"""

import os
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, date, timedelta
from supabase import create_client, Client


class SentimentSupabaseClient:
    """èˆ†æƒ…ç›‘æ§Supabaseå®¢æˆ·ç«¯"""

    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–Supabaseå®¢æˆ·ç«¯"""
        supabase_config = config.get("supabase", {})
        url = supabase_config.get("url") or os.getenv("SUPABASE_URL")
        key = supabase_config.get("key") or os.getenv("SUPABASE_KEY")

        if not url or not key:
            raise ValueError("Supabase URL and key are required")

        self.client: Client = create_client(url, key)
        print(f"âœ… Supabase client initialized: {url}")

    # ==================== å†…å®¹æ•°æ®æ“ä½œ ====================

    def get_all_contents(self, platform: Optional[str] = None) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å†…å®¹ï¼ˆä¸é™æ—¥æœŸï¼‰

        Args:
            platform: å¹³å°è¿‡æ»¤ (xhs, douyin, bili, wb)ï¼ŒNone è¡¨ç¤ºå…¨å¹³å°

        Returns:
            å†…å®¹åˆ—è¡¨
        """
        query = self.client.table("contents").select("*")

        if platform:
            query = query.eq("platform", platform)

        try:
            response = query.execute()
            print(f"   Loaded {len(response.data)} items from {platform or 'all platforms'}")
            return response.data
        except Exception as e:
            print(f"âŒ Error loading all contents: {e}")
            return []

    def get_contents_by_date(
        self,
        target_date: date,
        platform: Optional[str] = None
    ) -> List[Dict]:
        """
        æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„å†…å®¹æ•°æ®

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            platform: å¹³å°è¿‡æ»¤ (xhs, douyin, bili, wb)

        Returns:
            å†…å®¹åˆ—è¡¨
        """
        # ç”±äºpublish_timeå­—æ®µå¯èƒ½æ˜¯ç§’çº§æˆ–æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥è¯¢æ‰€æœ‰æ•°æ®ç„¶åæ‰‹åŠ¨è¿‡æ»¤
        query = self.client.table("contents").select("*")

        if platform:
            query = query.eq("platform", platform)

        try:
            response = query.execute()

            # æ‰‹åŠ¨è¿‡æ»¤æ—¥æœŸ
            filtered_data = []
            for item in response.data:
                pub_time = item.get("publish_time")
                if pub_time:
                    # å¤„ç†ä¸¤ç§æ—¶é—´æˆ³æ ¼å¼
                    ts = pub_time if pub_time < 10000000000 else pub_time / 1000
                    try:
                        dt = datetime.fromtimestamp(ts)
                        if dt.date() == target_date:
                            filtered_data.append(item)
                    except:
                        pass

            print(f"   Loaded {len(filtered_data)} items from {platform or 'all platforms'}")
            return filtered_data

        except Exception as e:
            print(f"âŒ Error loading contents: {e}")
            return []

    def get_contents_by_date_range(
        self,
        start_date: date,
        end_date: date,
        platform: Optional[str] = None
    ) -> List[Dict]:
        """æŸ¥è¯¢æ—¥æœŸèŒƒå›´çš„å†…å®¹"""
        start_ts = int(datetime.combine(start_date, datetime.min.time()).timestamp())
        end_ts = int(datetime.combine(end_date, datetime.max.time()).timestamp())

        query = self.client.table("contents")\
            .select("*")\
            .gte("publish_time", start_ts)\
            .lte("publish_time", end_ts)

        if platform:
            query = query.eq("platform", platform)

        try:
            response = query.execute()
            return response.data
        except Exception as e:
            print(f"âŒ Error loading contents: {e}")
            return []

    def get_contents_by_keyword(
        self,
        keyword: str,
        start_date: Optional[date] = None,
        limit: int = 100
    ) -> List[Dict]:
        """æŸ¥è¯¢åŒ…å«ç‰¹å®šå…³é”®è¯çš„å†…å®¹"""
        query = self.client.table("contents")\
            .select("*")\
            .eq("source_keyword", keyword)\
            .order("publish_time", desc=True)\
            .limit(limit)

        if start_date:
            start_ts = int(datetime.combine(start_date, datetime.min.time()).timestamp())
            query = query.gte("publish_time", start_ts)

        try:
            response = query.execute()
            return response.data
        except Exception as e:
            print(f"âŒ Error loading by keyword: {e}")
            return []

    # ==================== è¯„è®ºæ•°æ®æ“ä½œ ====================

    def get_comments_by_content_ids(
        self,
        content_ids: List[str]
    ) -> Dict[str, List[Dict]]:
        """
        è·å–æŒ‡å®šå†…å®¹çš„è¯„è®º

        Returns:
            {content_id: [comment1, comment2, ...]}
        """
        if not content_ids:
            return {}

        try:
            response = self.client.table("comments")\
                .select("*")\
                .in_("content_id", content_ids)\
                .execute()

            # æŒ‰content_idåˆ†ç»„
            comments_by_content = {}
            for comment in response.data:
                content_id = comment.get("content_id")
                if content_id not in comments_by_content:
                    comments_by_content[content_id] = []
                comments_by_content[content_id].append(comment)

            return comments_by_content
        except Exception as e:
            print(f"âŒ Error loading comments: {e}")
            return {}

    # ==================== æ•°æ®è½¬æ¢ ====================

    def convert_to_legacy_format(self, items: List[Dict], platform: str) -> List[Dict]:
        """
        å°†Supabaseæ•°æ®è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰

        Args:
            items: Supabaseæ•°æ®
            platform: å¹³å°æ ‡è¯†

        Returns:
            å…¼å®¹æ—§æ ¼å¼çš„æ•°æ®åˆ—è¡¨
        """
        converted = []

        for item in items:
            if platform == "xhs":
                converted_item = {
                    "note_id": item.get("content_id"),
                    "type": item.get("content_type", "normal"),
                    "title": item.get("title", ""),
                    "desc": item.get("description", ""),
                    "note_url": item.get("content_url", ""),
                    "time": item.get("publish_time", 0) * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                    "user_id": item.get("user_id", ""),
                    "nickname": item.get("nickname", ""),
                    "avatar": item.get("avatar", ""),
                    "liked_count": str(item.get("liked_count", 0)),
                    "comment_count": str(item.get("comment_count", 0)),
                    "share_count": str(item.get("share_count", 0)),
                    "collected_count": str(item.get("collected_count", 0)),
                    "tag_list": "",  # ä»platform_dataæå–
                    "ip_location": item.get("ip_location", ""),
                    "source_keyword": item.get("source_keyword", ""),
                }

            elif platform == "dy" or platform == "douyin":
                converted_item = {
                    "aweme_id": item.get("content_id"),
                    "aweme_type": "0" if item.get("content_type") == "video" else "1",
                    "title": item.get("title", ""),
                    "desc": item.get("description", ""),
                    "aweme_url": item.get("content_url", ""),
                    "create_time": item.get("publish_time", 0),
                    "user_id": item.get("user_id", ""),
                    "nickname": item.get("nickname", ""),
                    "avatar": item.get("avatar", ""),
                    "liked_count": str(item.get("liked_count", 0)),
                    "comment_count": str(item.get("comment_count", 0)),
                    "share_count": str(item.get("share_count", 0)),
                    "collected_count": str(item.get("collected_count", 0)),
                }

            elif platform == "bili":
                converted_item = {
                    "video_id": item.get("content_id"),
                    "video_type": item.get("content_type", "video"),
                    "title": item.get("title", ""),
                    "desc": item.get("description", ""),
                    "video_url": item.get("content_url", ""),
                    "create_time": item.get("publish_time", 0),
                    "user_id": item.get("user_id", ""),
                    "nickname": item.get("nickname", ""),
                    "liked_count": str(item.get("liked_count", 0)),
                    "video_comment": str(item.get("comment_count", 0)),
                    "video_share_count": str(item.get("share_count", 0)),
                    "video_favorite_count": str(item.get("collected_count", 0)),
                    "video_play_count": str(item.get("platform_data", {}).get("video_play_count", 0)),
                }

            elif platform == "wb":
                converted_item = {
                    "mblog_id": item.get("content_id"),
                    "mblog_text": item.get("description", ""),
                    "mblog_url": item.get("content_url", ""),
                    "mblog_created_at": item.get("publish_time", 0),
                    "user_id": item.get("user_id", ""),
                    "nickname": item.get("nickname", ""),
                    "avatar": item.get("avatar", ""),
                    "attitudes_count": str(item.get("liked_count", 0)),
                    "comments_count": str(item.get("comment_count", 0)),
                    "reposts_count": str(item.get("share_count", 0)),
                }

            else:
                continue

            converted.append(converted_item)

        return converted

    # ==================== ç»Ÿè®¡æŸ¥è¯¢ ====================

    def get_platform_stats(
        self,
        start_date: date,
        end_date: date
    ) -> Dict[str, int]:
        """è·å–å¹³å°åˆ†å¸ƒç»Ÿè®¡"""
        contents = self.get_contents_by_date_range(start_date, end_date)

        stats = {}
        for item in contents:
            platform = item.get("platform", "unknown")
            stats[platform] = stats.get(platform, 0) + 1

        return stats

    def get_top_contents(
        self,
        start_date: date,
        end_date: date,
        limit: int = 10
    ) -> List[Dict]:
        """è·å–é«˜äº’åŠ¨å†…å®¹"""
        contents = self.get_contents_by_date_range(start_date, end_date)

        # è®¡ç®—æ€»äº’åŠ¨é‡
        for item in contents:
            item["total_engagement"] = (
                item.get("liked_count", 0) +
                item.get("comment_count", 0) +
                item.get("share_count", 0) +
                item.get("collected_count", 0)
            )

        # æ’åºå¹¶è¿”å›top N
        sorted_contents = sorted(
            contents,
            key=lambda x: x["total_engagement"],
            reverse=True
        )

        return sorted_contents[:limit]


if __name__ == "__main__":
    # æµ‹è¯•
    print("=" * 70)
    print("Testing Supabase Client")
    print("=" * 70)

    import os
    config = {
        "supabase": {
            "url": os.environ.get("SUPABASE_URL", "https://dfpijqpgsupvdmidztup.supabase.co"),
            "key": os.environ.get("SUPABASE_KEY", "")
        }
    }

    client = SentimentSupabaseClient(config)

    # æµ‹è¯•æŸ¥è¯¢
    today = date.today()
    yesterday = today - timedelta(days=1)

    print(f"\nğŸ“Š Testing query for {yesterday}...")
    contents = client.get_contents_by_date(yesterday)
    print(f"   Found {len(contents)} items")

    if contents:
        print(f"\nğŸ“ Sample item:")
        sample = contents[0]
        print(f"   Platform: {sample.get('platform')}")
        print(f"   Title: {sample.get('title', '')[:60]}...")
        print(f"   URL: {sample.get('content_url', '')[:60]}...")

    print("\nâœ… Test complete!")
