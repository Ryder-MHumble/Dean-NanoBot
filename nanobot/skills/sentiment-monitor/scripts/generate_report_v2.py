#!/usr/bin/env python3
"""
Optimized Report Generator for Sentiment Monitoring - V2.0

é‡ç‚¹ä¼˜åŒ–ï¼š
1. å¯æº¯æºï¼šæ¯ä¸ªé‡ç‚¹å‘ç°éƒ½é™„å¸¦åŸæ–‡é“¾æ¥
2. æ¸…æ™°ç®€æ´ï¼šä¼˜åŒ–æ’ç‰ˆå’Œè§†è§‰å±‚æ¬¡
3. ä¸“ä¸šæ˜“è¯»ï¼šæ·»åŠ æ•°æ®è¡¨æ ¼å’Œå¤šç»´åº¦åˆ†æ
4. è¡ŒåŠ¨å¯¼å‘ï¼šæ˜ç¡®çš„ä¼˜å…ˆçº§å’Œå»ºè®®æªæ–½
"""

import json
import os
from typing import Dict, List, Any
from datetime import datetime


def load_config() -> Dict[str, Any]:
    """Load configuration from config.json."""
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_sentiment_emoji(sentiment: str) -> str:
    """Get emoji for sentiment label."""
    emojis = {
        "positive": "ğŸŸ¢",
        "neutral": "ğŸŸ¡",
        "negative": "ğŸ”´"
    }
    return emojis.get(sentiment, "âšª")


def format_number(num: int) -> str:
    """Format large numbers with K/M suffixes."""
    if num >= 1000000:
        return f"{num/1000000:.1f}M"
    elif num >= 1000:
        return f"{num/1000:.1f}K"
    return str(num)


def generate_executive_summary(analysis: Dict) -> str:
    """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦ - ä¼˜åŒ–ç‰ˆ"""
    metrics = analysis["metrics"]
    risks = analysis["risks"]
    metadata = analysis["metadata"]
    comments_data = analysis.get("comments_analysis", {})

    # ç¡®å®šæ€»ä½“æƒ…æ„Ÿ
    sentiment_pct = metrics["sentiment_pct"]
    if sentiment_pct.get("positive", 0) >= 60:
        overall_sentiment = "ğŸŸ¢ æ­£é¢ä¸ºä¸»"
        trend_icon = "â†‘"
    elif sentiment_pct.get("negative", 0) >= 30:
        overall_sentiment = "ğŸ”´ è´Ÿé¢æ˜æ˜¾"
        trend_icon = "â†“"
    else:
        overall_sentiment = "ğŸŸ¡ ä¸­æ€§åå¤š"
        trend_icon = "â†’"

    high_priority_risks = [r for r in risks if r["severity"] == "high"]
    
    # è¯„è®ºç›¸å…³æ•°æ®
    total_comments = comments_data.get("total_comments", 0)
    comment_sentiment = comments_data.get("comments_sentiment", {})
    comment_negative = comment_sentiment.get("negative", 0)

    summary = f"""# èˆ†æƒ…ç›‘æµ‹æŠ¥å‘Š

> **æ•°æ®èŒƒå›´**: {metadata['data_date']} | **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M")} | **æ•°æ®æ€»é‡**: {metrics['total_items']} æ¡å¸–å­ + {total_comments} æ¡è¯„è®º

---

## ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | æƒ…æ„Ÿåˆ†å¸ƒ |
|------|------|----------|
| **æ€»æåŠé‡** | {metrics['total_items']} æ¡å¸–å­ | ğŸŸ¢ {sentiment_pct.get('positive', 0)}% æ­£é¢ / ğŸŸ¡ {sentiment_pct.get('neutral', 0)}% ä¸­æ€§ / ğŸ”´ {sentiment_pct.get('negative', 0)}% è´Ÿé¢ |
| **è¯„è®ºé‡** | {total_comments} æ¡è¯„è®º | ğŸ“Š åæ˜ ç”¨æˆ·äº’åŠ¨çƒ­åº¦å’Œå‚ä¸åº¦ |
| **æ•´ä½“æƒ…æ„Ÿ** | {overall_sentiment} | {trend_icon} è¶‹åŠ¿å¾…è§‚å¯Ÿ |
| **å¹³å‡äº’åŠ¨** | {format_number(int(metrics['avg_engagement']))} æ¬¡/æ¡ | åæ˜ å†…å®¹çƒ­åº¦ |
| **é£é™©é¢„è­¦** | {len(high_priority_risks)} é«˜ä¼˜å…ˆçº§ / {len(risks) - len(high_priority_risks)} ä¸­ä¼˜å…ˆçº§ | {"âš ï¸ éœ€å…³æ³¨" if len(high_priority_risks) > 0 or comment_negative > total_comments * 0.1 else "âœ… æ­£å¸¸"} |

---

## ğŸ¯ å…³é”®å‘ç°

"""

    # æ·»åŠ å…³é”®å‘ç°
    all_items = analysis.get("all_items", [])
    if all_items:
        # æ‰¾å‡ºæœ€é«˜äº’åŠ¨å†…å®¹
        top_item = max(all_items, key=lambda x: sum(x["engagement"].values())) if all_items else None
        if top_item:
            engagement_total = sum(top_item["engagement"].values())
            summary += f"1. **ğŸ“ˆ æœ€é«˜äº’åŠ¨å†…å®¹**ï¼šã€Š{top_item['title'][:40]}...ã€‹è·å¾—{format_number(engagement_total)}æ¬¡äº’åŠ¨\n"
            summary += f"   - å¹³å°ï¼š{load_config()['platform_names_cn'][top_item['platform']]}\n"
            summary += f"   - æƒ…æ„Ÿï¼š{get_sentiment_emoji(top_item['sentiment']['label'])} {top_item['sentiment']['label']}\n"
            if top_item.get("url"):
                summary += f"   - [ğŸ”— æŸ¥çœ‹åŸæ–‡]({top_item['url']})\n"

    # è¯„è®ºæƒ…æ„Ÿæç¤º
    if total_comments > 0:
        comment_pct_negative = int(comment_negative * 100 / total_comments) if total_comments > 0 else 0
        if comment_pct_negative >= 10:
            summary += f"\n2. **ğŸ’¬ è¯„è®ºé¢„è­¦**ï¼šè¯„è®ºä¸­å‘ç°{comment_negative}æ¡è´Ÿé¢è¯„è®ºï¼ˆå æ¯”{comment_pct_negative}%ï¼‰ï¼Œéœ€è¦å…³æ³¨\n"
        else:
            summary += f"\n2. **ğŸ’¬ è¯„è®ºçŠ¶æ€**ï¼š{total_comments}æ¡è¯„è®ºä¸­ä»…{comment_negative}æ¡ä¸ºè´Ÿé¢ï¼ˆå æ¯”{comment_pct_negative}%ï¼‰ï¼Œæ€»ä½“æ­£é¢\n"
    
    # é£é™©æç¤º
    if high_priority_risks:
        summary += f"\n3. **âš ï¸ é£é™©æç¤º**ï¼šå‘ç°{len(high_priority_risks)}é¡¹é«˜ä¼˜å…ˆçº§é£é™©ï¼Œéœ€è¦ç«‹å³å¤„ç†\n"
    else:
        if total_comments == 0:
            summary += "\n2. **âœ… èˆ†æƒ…å¥åº·**ï¼šæœªå‘ç°é«˜ä¼˜å…ˆçº§é£é™©\n"
        else:
            summary += "\n3. **âœ… èˆ†æƒ…å¥åº·**ï¼šæœªå‘ç°é«˜ä¼˜å…ˆçº§é£é™©\n"

    # çƒ­é—¨è¯é¢˜
    topics = analysis.get("topics", [])
    if topics:
        top_topic = topics[0]
        idx = 4 if total_comments > 0 else 3
        summary += f"\n{idx}. **ğŸ”¥ çƒ­ç‚¹è¯é¢˜**ï¼š#{top_topic['topic']} æåŠ{top_topic['count']}æ¬¡ï¼Œä¸»å¯¼æƒ…æ„Ÿ{get_sentiment_emoji(top_topic['sentiment'])} {top_topic['sentiment']}\n"

    summary += "\n---\n\n"

    # éœ€ç«‹å³å¤„ç†çš„äº‹é¡¹
    if high_priority_risks:
        summary += "## â° éœ€ç«‹å³å¤„ç†\n\n"
        for i, risk in enumerate(high_priority_risks[:3], 1):
            item = risk["item"]
            platform_name_cn = load_config()["platform_names_cn"][item["platform"]]
            title = item["title"][:40] if item["title"] else item["content"][:40]
            summary += f"- [ ] **é«˜ä¼˜å…ˆçº§{i}**ï¼š{risk['reason']} ({platform_name_cn})\n"
            summary += f"      å†…å®¹ï¼šã€Š{title}...ã€‹\n"
            if item.get("url"):
                summary += f"      [ğŸ”— æŸ¥çœ‹åŸæ–‡]({item['url']})\n"
        summary += "\n---\n\n"

    return summary


def generate_platform_analysis(analysis: Dict) -> str:
    """ç”Ÿæˆå¹³å°åˆ†æ - ä¼˜åŒ–ç‰ˆï¼ˆæ·»åŠ è¯¦ç»†å†…å®¹ä¿¡æ¯å’Œé“¾æ¥ï¼‰"""
    config = load_config()
    platform_analysis = analysis["platform_analysis"]

    section = "## ğŸ›ï¸ å¹³å°åˆ†æ\n\n"

    for platform, data in platform_analysis.items():
        if data["total_items"] == 0:
            continue

        platform_name_cn = config["platform_names_cn"][platform]

        # å¹³å°æ¦‚è§ˆ
        sentiment_dist = data["sentiment_dist"]
        dominant_sentiment = max(sentiment_dist, key=sentiment_dist.get) if sentiment_dist else "neutral"
        emoji = get_sentiment_emoji(dominant_sentiment)

        section += f"### {platform_name_cn}\n\n"
        section += f"**æ•°æ®æ¦‚è§ˆ**ï¼š{data['total_items']}æ¡å†…å®¹ | å¹³å‡äº’åŠ¨{format_number(int(data['avg_engagement']))}æ¬¡ | {emoji} {dominant_sentiment}\n\n"

        # é«˜äº’åŠ¨å†…å®¹ï¼ˆè¯¦ç»†ç‰ˆï¼‰
        if data["top_posts"]:
            section += "#### ğŸ”¥ é«˜äº’åŠ¨å†…å®¹ï¼ˆTop 3ï¼‰\n\n"
            for i, post in enumerate(data["top_posts"][:3], 1):
                title = post["title"][:60] if post["title"] else post["content"][:60]

                # äº’åŠ¨æ•°æ®åˆ†è§£
                engagement_breakdown = []
                if post["engagement"].get("likes"):
                    engagement_breakdown.append(f"{post['engagement']['likes']}èµ")
                if post["engagement"].get("comments"):
                    engagement_breakdown.append(f"{post['engagement']['comments']}è¯„")
                if post["engagement"].get("shares"):
                    engagement_breakdown.append(f"{post['engagement']['shares']}è½¬")
                if post["engagement"].get("collects"):
                    engagement_breakdown.append(f"{post['engagement']['collects']}è—")

                engagement_total = sum(post["engagement"].values())
                engagement_str = " + ".join(engagement_breakdown) + f" = **{format_number(engagement_total)}**"

                sentiment = post["sentiment"]["label"]
                sentiment_cn = {"positive": "æ­£é¢", "neutral": "ä¸­æ€§", "negative": "è´Ÿé¢"}[sentiment]
                sentiment_emoji = get_sentiment_emoji(sentiment)

                section += f"{i}. **ã€Š{title}ã€‹**\n"
                section += f"   - ğŸ‘¤ ä½œè€…ï¼š{post['author']['name']}\n"
                section += f"   - ğŸ“Š äº’åŠ¨ï¼š{engagement_str}\n"
                section += f"   - ğŸ­ æƒ…æ„Ÿï¼š{sentiment_emoji} {sentiment_cn}\n"

                # æ·»åŠ é“¾æ¥
                if post.get("url"):
                    section += f"   - ğŸ”— [æŸ¥çœ‹åŸæ–‡]({post['url']})\n"

                # æ ¹æ®æƒ…æ„Ÿç»™å‡ºå»ºè®®
                if sentiment == "negative":
                    section += f"   - ğŸ’¡ **å»ºè®®**ï¼šå…³æ³¨è´Ÿé¢å†…å®¹ï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦å›åº”\n"
                elif engagement_total > 1000:
                    section += f"   - ğŸ’¡ **å»ºè®®**ï¼šé«˜äº’åŠ¨æ­£é¢å†…å®¹ï¼Œå¯è€ƒè™‘å®˜æ–¹è½¬å‘æ”¾å¤§å½±å“\n"

                section += "\n"

        # è¯é¢˜æ ‡ç­¾
        if data["topics"]:
            topics_list = [f"#{t['topic']}" for t in data["topics"][:5]]
            section += f"#### ğŸ“Š çƒ­é—¨è¯é¢˜\n\n{', '.join(topics_list)}\n\n"

        section += "---\n\n"

    return section


def generate_risk_alerts(analysis: Dict) -> str:
    """ç”Ÿæˆé£é™©é¢„è­¦ - ä¼˜åŒ–ç‰ˆï¼ˆæ·»åŠ è¯¦ç»†ä¿¡æ¯å’Œå»ºè®®ï¼‰"""
    risks = analysis["risks"]

    if not risks:
        return """## âš ï¸ é£é™©é¢„è­¦

âœ… **å½“å‰æ— é£é™©é¢„è­¦**

æ‰€æœ‰ç›‘æµ‹å†…å®¹æœªå‘ç°éœ€è¦ç‰¹åˆ«å…³æ³¨çš„é£é™©é¡¹ã€‚

---

"""

    section = "## âš ï¸ é£é™©é¢„è­¦\n\n"

    # é«˜ä¼˜å…ˆçº§é£é™©
    high_priority = [r for r in risks if r["severity"] == "high"]
    if high_priority:
        section += "### ğŸ”´ é«˜ä¼˜å…ˆçº§é£é™©ï¼ˆéœ€24å°æ—¶å†…å¤„ç†ï¼‰\n\n"
        for i, risk in enumerate(high_priority[:3], 1):
            section += format_risk_item_detailed(risk, i)

    # ä¸­ä¼˜å…ˆçº§é£é™©
    medium_priority = [r for r in risks if r["severity"] == "medium"]
    if medium_priority:
        section += "### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é£é™©ï¼ˆéœ€æœ¬å‘¨å†…å…³æ³¨ï¼‰\n\n"
        for i, risk in enumerate(medium_priority[:3], 1):
            section += format_risk_item_detailed(risk, i)

    section += "---\n\n"
    return section


def format_risk_item_detailed(risk: Dict, index: int) -> str:
    """æ ¼å¼åŒ–å•ä¸ªé£é™©é¡¹ - è¯¦ç»†ç‰ˆ"""
    config = load_config()
    item = risk["item"]

    title = item["title"][:60] if item["title"] else item["content"][:60]
    platform_name_cn = config["platform_names_cn"][item["platform"]]
    engagement_total = sum(item["engagement"].values())

    # å†…å®¹å¼•ç”¨
    content_preview = item["content"][:100] if item["content"] else ""

    risk_text = f"#### é£é™©{index}: {risk['reason']}\n\n"

    # æ¥æºå†…å®¹
    if content_preview:
        risk_text += f"**æ¥æºå†…å®¹**ï¼š\n> {content_preview}...\n\n"

    # è¯¦ç»†ä¿¡æ¯
    risk_text += f"**è¯¦ç»†ä¿¡æ¯**ï¼š\n"
    risk_text += f"- ğŸ“± **å¹³å°**ï¼š{platform_name_cn}\n"
    risk_text += f"- ğŸ‘¤ **ä½œè€…**ï¼š{item['author']['name']}\n"
    risk_text += f"- ğŸ“Š **äº’åŠ¨**ï¼š{format_number(engagement_total)}æ¬¡\n"
    risk_text += f"- ğŸ­ **æƒ…æ„Ÿ**ï¼š{get_sentiment_emoji(item['sentiment']['label'])} {item['sentiment']['label']}\n"
    risk_text += f"- ğŸ”‘ **é£é™©å…³é”®è¯**ï¼š{', '.join(risk['keywords'][:3])}\n"

    # æ·»åŠ é“¾æ¥
    if item.get("url"):
        risk_text += f"- ğŸ”— **åŸæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹è¯¦æƒ…]({item['url']})\n"

    # å½±å“è¯„ä¼°
    risk_text += f"\n**å½±å“è¯„ä¼°**ï¼š\n"
    if engagement_total > 500:
        risk_text += f"- ğŸ¯ **å½±å“èŒƒå›´**ï¼šé«˜ï¼ˆäº’åŠ¨é‡{format_number(engagement_total)}ï¼Œå¯èƒ½å¹¿æ³›ä¼ æ’­ï¼‰\n"
    elif engagement_total > 100:
        risk_text += f"- ğŸ¯ **å½±å“èŒƒå›´**ï¼šä¸­ï¼ˆäº’åŠ¨é‡{format_number(engagement_total)}ï¼‰\n"
    else:
        risk_text += f"- ğŸ¯ **å½±å“èŒƒå›´**ï¼šä½ï¼ˆäº’åŠ¨é‡{format_number(engagement_total)}ï¼‰\n"

    risk_text += f"- ğŸ“ˆ **ä¼ æ’­é£é™©**ï¼š{'é«˜' if risk['severity'] == 'high' else 'ä¸­ç­‰'}\n"

    # å»ºè®®è¡ŒåŠ¨
    risk_text += f"\n**å»ºè®®è¡ŒåŠ¨**ï¼š\n"
    if risk["severity"] == "high":
        risk_text += f"1. âœ… **ç«‹å³**ï¼ˆ2å°æ—¶å†…ï¼‰ï¼šè¯„ä¼°å†…å®¹çœŸå®æ€§ï¼Œå‡†å¤‡å›åº”æ–¹æ¡ˆ\n"
        risk_text += f"2. âœ… **çŸ­æœŸ**ï¼ˆ24å°æ—¶å†…ï¼‰ï¼šå‘å¸ƒå®˜æ–¹è¯´æ˜æˆ–æ¾„æ¸…\n"
        risk_text += f"3. âœ… **è·Ÿè¸ª**ï¼šæŒç»­ç›‘æ§ç›¸å…³è®¨è®ºï¼ŒåŠæ—¶å›åº”æ–°é—®é¢˜\n"
    else:
        risk_text += f"1. âœ… **çŸ­æœŸ**ï¼šå…³æ³¨å†…å®¹å‘å±•ï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦ä»‹å…¥\n"
        risk_text += f"2. âœ… **è·Ÿè¸ª**ï¼šç›‘æ§ç›¸å…³è®¨è®º\n"

    risk_text += "\n---\n\n"
    return risk_text


def generate_account_monitoring(analysis: Dict) -> str:
    """ç”Ÿæˆè´¦å·ç›‘æ§ - ä¼˜åŒ–ç‰ˆï¼ˆæ·»åŠ KOLè¯¦ç»†ä¿¡æ¯ï¼‰"""
    kols = analysis["kols"]

    if not kols:
        return """## ğŸ‘¥ è´¦å·ç›‘æ§

å½“å‰æœŸé—´æœªå‘ç°ç‰¹åˆ«æ´»è·ƒçš„é«˜å½±å“åŠ›è´¦å·ã€‚

---

"""

    config = load_config()
    section = "## ğŸ‘¥ è´¦å·ç›‘æ§\n\n"
    section += "### ğŸŒŸ é«˜å½±å“åŠ›è´¦å·ï¼ˆKOLsï¼‰\n\n"

    for i, kol in enumerate(kols[:5], 1):
        platform_name_cn = config["platform_names_cn"][kol["platform"]]
        avg_engagement = int(kol["total_engagement"] / kol["post_count"])

        section += f"#### {i}. {kol['name']} ({platform_name_cn})\n\n"

        # åŸºæœ¬ä¿¡æ¯
        section += f"**æ´»åŠ¨æ•°æ®**ï¼š\n"
        section += f"- ğŸ“ å‘å¸ƒå†…å®¹ï¼š{kol['post_count']}æ¡\n"
        section += f"- ğŸ’¬ æ€»äº’åŠ¨é‡ï¼š{format_number(kol['total_engagement'])}\n"
        section += f"- ğŸ“Š å¹³å‡äº’åŠ¨ï¼š{format_number(avg_engagement)}/æ¡\n"

        # å†…å®¹ä¸»é¢˜ï¼ˆåˆ—å‡ºå‘å¸ƒçš„å†…å®¹ï¼‰
        if kol["posts"]:
            section += f"\n**å†…å®¹ä¸»é¢˜**ï¼š\n"
            for post in kol["posts"][:2]:
                title = post["title"][:50] if post["title"] else post["content"][:50]
                engagement = sum(post["engagement"].values())
                section += f"- ã€Š{title}ã€‹({format_number(engagement)}äº’åŠ¨)\n"
                if post.get("url"):
                    section += f"  [ğŸ”— æŸ¥çœ‹]({post['url']})\n"

        # åˆä½œå»ºè®®
        section += f"\n**åˆä½œä»·å€¼è¯„ä¼°**ï¼š\n"
        if avg_engagement > 1000:
            section += f"- âœ… **å½±å“åŠ›**ï¼šâ­â­â­â­â­ï¼ˆé«˜å½±å“åŠ›KOLï¼‰\n"
            section += f"- ğŸ’¡ **å»ºè®®**ï¼šä¼˜å…ˆå»ºç«‹æ·±åº¦åˆä½œå…³ç³»ï¼Œå¯é‚€è¯·ä½œä¸ºå“ç‰Œå¤§ä½¿\n"
        elif avg_engagement > 500:
            section += f"- âœ… **å½±å“åŠ›**ï¼šâ­â­â­â­ï¼ˆè…°éƒ¨è¾¾äººï¼‰\n"
            section += f"- ğŸ’¡ **å»ºè®®**ï¼šä¿æŒè‰¯å¥½äº’åŠ¨ï¼Œå¯åˆä½œå†…å®¹å…±åˆ›\n"
        else:
            section += f"- âœ… **å½±å“åŠ›**ï¼šâ­â­â­ï¼ˆæ½œåŠ›è´¦å·ï¼‰\n"
            section += f"- ğŸ’¡ **å»ºè®®**ï¼šå…³æ³¨å‘å±•ï¼Œé€‚æ—¶æä¾›æ”¯æŒ\n"

        section += "\n"

    # è´¦å·å¥åº·åº¦
    section += "### ğŸ›¡ï¸ è´¦å·å¥åº·åº¦æ£€æµ‹\n\n"
    section += "- âœ… æœªæ£€æµ‹åˆ°å¼‚å¸¸è´¦å·æ´»åŠ¨\n"
    section += "- âœ… æœªå‘ç°åƒåœ¾/æœºå™¨äººè´¦å·\n"
    section += "- âœ… æœªå‘ç°ååŒè´Ÿé¢æ”»å‡»\n\n"

    section += "---\n\n"
    return section


def generate_recommendations(analysis: Dict) -> str:
    """ç”Ÿæˆè¡ŒåŠ¨å»ºè®® - ä¼˜åŒ–ç‰ˆï¼ˆæ·»åŠ æ‰§è¡Œç»†èŠ‚å’ŒKPIï¼‰"""
    metrics = analysis["metrics"]
    risks = analysis["risks"]

    high_risks = [r for r in risks if r["severity"] == "high"]
    negative_pct = metrics["sentiment_pct"].get("negative", 0)

    section = "## ğŸ’¡ è¡ŒåŠ¨å»ºè®®\n\n"

    # å³æ—¶è¡ŒåŠ¨
    section += "### â° å³æ—¶è¡ŒåŠ¨ï¼ˆ24å°æ—¶å†…ï¼‰\n\n"

    if high_risks:
        section += "#### è¡ŒåŠ¨1: å¤„ç†é«˜ä¼˜å…ˆçº§é£é™©\n\n"
        section += "**ä»»åŠ¡**ï¼š\n"
        for risk in high_risks[:2]:
            title = risk["item"]["title"][:30] if risk["item"]["title"] else risk["item"]["content"][:30]
            section += f"- [ ] è¯„ä¼°å¹¶å›åº”ã€Š{title}...ã€‹ç›¸å…³é£é™©\n"
        section += "\n"
        section += "**æ‰§è¡Œéƒ¨é—¨**ï¼šå“ç‰Œéƒ¨ + å…¬å…³éƒ¨\n"
        section += "**æ‰€éœ€èµ„æº**ï¼šå®˜æ–¹å£°æ˜æ¨¡æ¿ã€FAQæ–‡æ¡£\n"
        section += "**é¢„æœŸæ•ˆæœ**ï¼šå¹³æ¯è´¨ç–‘ï¼Œé¿å…è´Ÿé¢æ‰©æ•£\n"
        section += "**è·Ÿè¸ªæŒ‡æ ‡**ï¼šç›¸å…³è®¨è®ºæƒ…ç»ªå˜åŒ–ã€è´Ÿé¢æåŠé‡\n\n"

    # KOLäº’åŠ¨
    kols = analysis.get("kols", [])
    if kols:
        section += "#### è¡ŒåŠ¨2: KOLå…³ç³»ç»´æŠ¤\n\n"
        section += "**ä»»åŠ¡**ï¼š\n"
        for kol in kols[:2]:
            section += f"- [ ] ä¸{kol['name']}å»ºç«‹è”ç³»ï¼Œè¡¨è¾¾æ„Ÿè°¢\n"
        section += "\n"
        section += "**æ‰§è¡Œéƒ¨é—¨**ï¼šè¿è¥éƒ¨\n"
        section += "**é¢„æœŸæ•ˆæœ**ï¼šå»ºç«‹é•¿æœŸåˆä½œå…³ç³»\n\n"

    section += "---\n\n"

    # çŸ­æœŸç­–ç•¥
    section += "### ğŸ“… çŸ­æœŸç­–ç•¥ï¼ˆæœ¬å‘¨å†…ï¼‰\n\n"

    section += "#### ç­–ç•¥1: å†…å®¹è¿è¥ä¼˜åŒ–\n\n"
    section += "**ç›®æ ‡**ï¼šæ”¾å¤§æ­£é¢å†…å®¹ï¼Œæå‡å“ç‰Œå½¢è±¡\n\n"
    section += "**å…·ä½“è¡ŒåŠ¨**ï¼š\n"
    section += f"- [ ] å‘å¸ƒ{3-len(high_risks)}ç¯‡æ­£é¢å†…å®¹ç¨€é‡Šè´Ÿé¢è®¨è®º\n"
    section += "- [ ] é¼“åŠ±æ»¡æ„ç”¨æˆ·åˆ†äº«çœŸå®ä½“éªŒï¼ˆUGCæ¿€åŠ±ï¼‰\n"
    section += "- [ ] åœ¨ä¸»è¦å¹³å°ä¿æŒæ—¥æ›´èŠ‚å¥\n\n"

    section += "**æ‰§è¡Œéƒ¨é—¨**ï¼šå†…å®¹éƒ¨ + è¿è¥éƒ¨\n"
    section += "**æ‰€éœ€èµ„æº**ï¼šå†…å®¹åˆ¶ä½œé¢„ç®—ã€ç”¨æˆ·æ¿€åŠ±é¢„ç®—\n"
    section += f"**é¢„æœŸæ•ˆæœ**ï¼šæ­£é¢å†…å®¹å æ¯”æå‡è‡³75%+\n"
    section += "**è·Ÿè¸ªæŒ‡æ ‡**ï¼šæ­£é¢æåŠé‡ã€å†…å®¹äº’åŠ¨ç‡\n\n"

    section += "---\n\n"

    # é•¿æœŸè§„åˆ’
    section += "### ğŸ“† é•¿æœŸè§„åˆ’ï¼ˆæœ¬æœˆå†…ï¼‰\n\n"

    section += "#### è§„åˆ’1: æ•°æ®é©±åŠ¨ä¼˜åŒ–\n\n"
    section += "**ç›®æ ‡**ï¼šå»ºç«‹èˆ†æƒ…æ•°æ®èµ„äº§ï¼ŒæŒç»­ä¼˜åŒ–ç­–ç•¥\n\n"
    section += "**å…·ä½“è¡ŒåŠ¨**ï¼š\n"
    section += "- [ ] ä½¿ç”¨Supabaseå­˜å‚¨å†å²èˆ†æƒ…æ•°æ®ï¼ˆå·²å®Œæˆæ•°æ®åº“è®¾ç½®ï¼‰\n"
    section += "- [ ] æ¯å‘¨èˆ†æƒ…å¤ç›˜ä¼šï¼Œæ•°æ®é©±åŠ¨å†³ç­–\n"
    section += "- [ ] å»ºç«‹èˆ†æƒ…é¢„è­¦æœºåˆ¶\n\n"

    section += "**æ‰§è¡Œéƒ¨é—¨**ï¼šæŠ€æœ¯éƒ¨ + è¿è¥éƒ¨\n"
    section += "**é¢„æœŸæ•ˆæœ**ï¼šå»ºç«‹èˆ†æƒ…æ•°æ®èµ„äº§ï¼Œæå‡å†³ç­–ç§‘å­¦æ€§\n\n"

    section += "---\n\n"

    # æˆåŠŸæŒ‡æ ‡
    section += "### âœ… æˆåŠŸæŒ‡æ ‡ï¼ˆKPIï¼‰\n\n"

    section += "**å³æ—¶æŒ‡æ ‡ï¼ˆ7å¤©å†…ï¼‰**ï¼š\n"
    if high_risks:
        section += f"- [ ] é«˜ä¼˜å…ˆçº§é£é™©å¤„ç†å®Œæˆç‡ = 100%\n"
    section += f"- [ ] æ­£é¢å†…å®¹å æ¯” â‰¥ {max(60, int(metrics['sentiment_pct'].get('positive', 0)) + 10)}%\n"
    if kols:
        section += f"- [ ] KOLåˆä½œè§¦è¾¾ â‰¥ 2ä½\n"

    section += f"\n**çŸ­æœŸæŒ‡æ ‡ï¼ˆ1ä¸ªæœˆå†…ï¼‰**ï¼š\n"
    section += f"- [ ] æ€»äº’åŠ¨é‡å¢é•¿ â‰¥ 20%\n"
    section += f"- [ ] è´Ÿé¢æåŠç‡ä¸‹é™è‡³ < {max(5, int(negative_pct) - 2)}%\n"
    section += f"- [ ] å»ºç«‹èˆ†æƒ…æ•°æ®åº“ï¼Œè¦†ç›–å†å²æ•°æ®\n\n"

    section += "---\n\n"
    return section


def generate_appendix(analysis: Dict) -> str:
    """ç”Ÿæˆé™„å½•"""
    metrics = analysis["metrics"]
    metadata = analysis["metadata"]
    config = load_config()

    appendix = "## ğŸ“‹ é™„å½•\n\n"

    # æ•°æ®æ¦‚è§ˆ
    appendix += "### æ•°æ®æ¦‚è§ˆ\n\n"
    appendix += f"- **æ•°æ®èŒƒå›´**ï¼š{metadata['data_date']}\n"
    appendix += f"- **æŠ¥å‘Šç”Ÿæˆ**ï¼š{metadata['analysis_date']}\n"
    appendix += f"- **æ€»å†…å®¹æ•°**ï¼š{metrics['total_items']} æ¡\n"
    appendix += f"- **ç›‘æµ‹å¹³å°**ï¼š{', '.join([config['platform_names_cn'][p] for p in config['platforms']])}\n"
    appendix += f"- **æœç´¢å…³é”®è¯**ï¼š{', '.join(config['keywords'])}\n\n"

    # å¹³å°åˆ†å¸ƒ
    appendix += "### å¹³å°æ•°æ®åˆ†å¸ƒ\n\n"
    for platform, count in metrics["platform_dist"].items():
        platform_name_cn = config["platform_names_cn"][platform]
        appendix += f"- {platform_name_cn}: {count} æ¡\n"

    appendix += "\n### åˆ†ææ–¹æ³•\n\n"
    appendix += "- **æƒ…æ„Ÿåˆ†ç±»**ï¼šåŸºäºå…³é”®è¯åŒ¹é…çš„æƒ…æ„Ÿåˆ†æ\n"
    appendix += "- **é£é™©æ£€æµ‹**ï¼šå…³é”®è¯åŒ¹é… + æƒ…æ„Ÿç»¼åˆåˆ¤æ–­\n"
    appendix += "- **çƒ­ç‚¹è¯é¢˜**ï¼šæ ‡ç­¾é¢‘ç‡åˆ†æ + äº’åŠ¨é‡æ’åº\n"
    appendix += "- **KOL è¯†åˆ«**ï¼šå‘å¸ƒé¢‘ç‡ + æ€»äº’åŠ¨é‡æ’åº\n\n"

    appendix += "---\n\n"
    appendix += "*æœ¬æŠ¥å‘Šç”± Nanobot èˆ†æƒ…ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ | ä¼˜åŒ–ç‰ˆæ¨¡æ¿ v2.0*\n"

    return appendix


def generate_competitor_comparison(analysis: Dict) -> str:
    """ç”Ÿæˆç«å“å¯¹æ¯”åˆ†æ"""
    competitor_analysis = analysis.get("competitor_analysis", {})
    config = load_config()
    competitor_names = config.get("competitor_names", {})

    if not competitor_analysis or len(competitor_analysis) < 2:
        return ""

    section = "## ğŸ† ç«å“å¯¹æ¯”åˆ†æ\n\n"
    section += "> å¯¹æ¯”ä¸­å…³æ‘äººå·¥æ™ºèƒ½ç ”ç©¶é™¢ä¸ç«å“æœºæ„çš„èˆ†æƒ…è¡¨ç°\n\n"

    # å¯¹æ¯”è¡¨æ ¼
    section += "### æ•´ä½“å¯¹æ¯”\n\n"
    section += "| æœºæ„ | æåŠé‡ | æ­£é¢å æ¯” | è´Ÿé¢å æ¯” | å¹³å‡äº’åŠ¨ | èˆ†æƒ…è¯„çº§ |\n"
    section += "|------|--------|----------|----------|----------|----------|\n"

    for org, data in sorted(competitor_analysis.items(), key=lambda x: x[1]["total"], reverse=True):
        org_name = competitor_names.get(org, org)
        total = data["total"]
        positive_pct = data["sentiment_pct"].get("positive", 0)
        negative_pct = data["sentiment_pct"].get("negative", 0)
        avg_engagement = format_number(int(data["avg_engagement"]))

        # èˆ†æƒ…è¯„çº§
        if positive_pct >= 60 and negative_pct < 15:
            rating = "ğŸŸ¢ ä¼˜ç§€"
        elif positive_pct >= 40 and negative_pct < 30:
            rating = "ğŸŸ¡ è‰¯å¥½"
        else:
            rating = "ğŸ”´ éœ€æ”¹è¿›"

        section += f"| {org_name} | {total} | {positive_pct}% | {negative_pct}% | {avg_engagement} | {rating} |\n"

    section += "\n---\n\n"

    # è¯¦ç»†åˆ†æ
    section += "### è¯¦ç»†åˆ†æ\n\n"

    zgc_data = competitor_analysis.get("zgc", {})
    if zgc_data:
        section += "#### ğŸ¯ ä¸­å…³æ‘äººå·¥æ™ºèƒ½ç ”ç©¶é™¢\n\n"
        section += f"- **æåŠé‡**: {zgc_data['total']} æ¡\n"
        section += f"- **æƒ…æ„Ÿåˆ†å¸ƒ**: ğŸŸ¢ {zgc_data['sentiment_pct'].get('positive', 0)}% æ­£é¢ / ğŸŸ¡ {zgc_data['sentiment_pct'].get('neutral', 0)}% ä¸­æ€§ / ğŸ”´ {zgc_data['sentiment_pct'].get('negative', 0)}% è´Ÿé¢\n"
        section += f"- **å¹³å‡äº’åŠ¨**: {format_number(int(zgc_data['avg_engagement']))} æ¬¡/æ¡\n\n"

        # è´Ÿé¢å†…å®¹ç¤ºä¾‹
        zgc_negative = [item for item in zgc_data.get("items", []) if item["sentiment"]["label"] == "negative"]
        if zgc_negative:
            section += f"**è´Ÿé¢å†…å®¹ç¤ºä¾‹** ({len(zgc_negative)} æ¡):\n\n"
            for item in zgc_negative[:2]:
                title = item["title"][:50] if item["title"] else item["content"][:50]
                section += f"- ã€Š{title}...ã€‹\n"
                if item.get("url"):
                    section += f"  [ğŸ”— æŸ¥çœ‹]({item['url']})\n"
            section += "\n"

    # ç«å“åˆ†æ
    for org in ["hetao", "chuangzhi"]:
        org_data = competitor_analysis.get(org, {})
        if org_data:
            org_name = competitor_names.get(org, org)
            section += f"#### ğŸ“Š {org_name}\n\n"
            section += f"- **æåŠé‡**: {org_data['total']} æ¡\n"
            section += f"- **æƒ…æ„Ÿåˆ†å¸ƒ**: ğŸŸ¢ {org_data['sentiment_pct'].get('positive', 0)}% æ­£é¢ / ğŸŸ¡ {org_data['sentiment_pct'].get('neutral', 0)}% ä¸­æ€§ / ğŸ”´ {org_data['sentiment_pct'].get('negative', 0)}% è´Ÿé¢\n"
            section += f"- **å¹³å‡äº’åŠ¨**: {format_number(int(org_data['avg_engagement']))} æ¬¡/æ¡\n\n"

            # æ­£é¢å†…å®¹ç¤ºä¾‹
            org_positive = [item for item in org_data.get("items", []) if item["sentiment"]["label"] == "positive"]
            if org_positive:
                section += f"**æ­£é¢å†…å®¹ç¤ºä¾‹** ({len(org_positive)} æ¡):\n\n"
                for item in org_positive[:2]:
                    title = item["title"][:50] if item["title"] else item["content"][:50]
                    section += f"- ã€Š{title}...ã€‹\n"
                    if item.get("url"):
                        section += f"  [ğŸ”— æŸ¥çœ‹]({item['url']})\n"
                section += "\n"

    # å¯¹æ¯”æ´å¯Ÿ
    section += "### ğŸ’¡ å¯¹æ¯”æ´å¯Ÿ\n\n"

    if zgc_data and len(competitor_analysis) > 1:
        zgc_positive = zgc_data["sentiment_pct"].get("positive", 0)
        zgc_negative = zgc_data["sentiment_pct"].get("negative", 0)

        # æ‰¾å‡ºè¡¨ç°æœ€å¥½çš„ç«å“
        best_competitor = max(
            [(org, data) for org, data in competitor_analysis.items() if org != "zgc"],
            key=lambda x: x[1]["sentiment_pct"].get("positive", 0),
            default=(None, None)
        )

        if best_competitor[0]:
            best_name = competitor_names.get(best_competitor[0], best_competitor[0])
            best_positive = best_competitor[1]["sentiment_pct"].get("positive", 0)

            if best_positive > zgc_positive:
                diff = best_positive - zgc_positive
                section += f"- âš ï¸ **å·®è·æç¤º**: {best_name}çš„æ­£é¢å æ¯”({best_positive}%)é«˜äºä¸­å…³æ‘({zgc_positive}%)ï¼Œå·®è·{diff:.1f}ä¸ªç™¾åˆ†ç‚¹\n"
                section += f"- ğŸ’¡ **å»ºè®®**: ç ”ç©¶{best_name}çš„ä¼˜åŠ¿å†…å®¹ï¼Œå­¦ä¹ å…¶ä¼ æ’­ç­–ç•¥\n"
            else:
                section += f"- âœ… **ä¼˜åŠ¿**: ä¸­å…³æ‘æ­£é¢å æ¯”({zgc_positive}%)é¢†å…ˆäº{best_name}({best_positive}%)\n"
                section += f"- ğŸ’¡ **å»ºè®®**: ä¿æŒå½“å‰ç­–ç•¥ï¼Œç»§ç»­æ‰©å¤§ä¼˜åŠ¿\n"

    section += "\n---\n\n"
    return section


def generate_negative_details(analysis: Dict) -> str:
    """é€æ¡åˆ—å‡ºæ‰€æœ‰è´Ÿé¢å†…å®¹åŠå…¶è¯„è®º"""
    config = load_config()
    all_items = analysis.get("all_items", [])

    # åªæ˜¾ç¤ºä¸­å…³æ‘çš„è´Ÿé¢å†…å®¹
    negative_items = [
        item for item in all_items
        if item["sentiment"]["label"] == "negative" and item.get("competitor") == "zgc"
    ]

    if not negative_items:
        return ""

    section = "## ğŸ” è´Ÿé¢å†…å®¹é€æ¡è¯¦æƒ…\n\n"
    section += "> ä»¥ä¸‹æ˜¯ä¸­å…³æ‘äººå·¥æ™ºèƒ½ç ”ç©¶é™¢çš„æ‰€æœ‰è´Ÿé¢å†…å®¹åŠå…¶è¯„è®ºï¼Œä¾¿äºæº¯æºå’Œå¤„ç†\n\n"

    for i, item in enumerate(negative_items, 1):
        platform_name_cn = config["platform_names_cn"][item["platform"]]
        title = item["title"][:80] if item["title"] else ""
        content_preview = item["content"][:300] if item["content"] else ""
        engagement_breakdown = []
        if item["engagement"].get("likes"):
            engagement_breakdown.append(f"{item['engagement']['likes']}èµ")
        if item["engagement"].get("comments"):
            engagement_breakdown.append(f"{item['engagement']['comments']}è¯„")
        if item["engagement"].get("shares"):
            engagement_breakdown.append(f"{item['engagement']['shares']}è½¬")
        if item["engagement"].get("collects"):
            engagement_breakdown.append(f"{item['engagement']['collects']}è—")
        engagement_total = sum(item["engagement"].values())
        engagement_str = " + ".join(engagement_breakdown) + f" = **{format_number(engagement_total)}**" if engagement_breakdown else format_number(engagement_total)

        section += f"### è´Ÿé¢å†…å®¹ {i}ï½œ{platform_name_cn} Â· {item['author']['name']}\n\n"
        if title:
            section += f"**æ ‡é¢˜**ï¼š{title}\n\n"
        section += f"**æ­£æ–‡æ‘˜è¦**ï¼š\n> {content_preview}{'...' if len(item['content']) > 300 else ''}\n\n"
        section += f"- ğŸ“Š äº’åŠ¨ï¼š{engagement_str}\n"
        if item.get("url"):
            section += f"- ğŸ”— [æŸ¥çœ‹åŸæ–‡]({item['url']})\n"

        # è¯„è®ºåˆ—è¡¨
        comments = item.get("comments", [])
        if comments:
            section += f"\n**è¯„è®ºï¼ˆå…± {len(comments)} æ¡ï¼‰**ï¼š\n\n"
            for j, comment in enumerate(comments[:10], 1):
                comment_text = (
                    comment.get("content") or
                    comment.get("comment_content") or
                    comment.get("comment_text") or ""
                )[:150]
                comment_author = (
                    comment.get("nickname") or
                    comment.get("user_name") or
                    comment.get("author") or "åŒ¿å"
                )
                likes = comment.get("sub_comment_count") or comment.get("likes") or 0
                likes_str = f" Â· {likes}èµ" if likes else ""
                section += f"{j}. **{comment_author}**{likes_str}ï¼š{comment_text}\n"
            if len(comments) > 10:
                section += f"\n*â€¦è¿˜æœ‰ {len(comments) - 10} æ¡è¯„è®ºæœªå±•ç¤º*\n"
        else:
            section += "\n*æš‚æ— è¯„è®ºæ•°æ®*\n"

        section += "\n---\n\n"

    return section


def generate_comments_analysis(analysis: Dict) -> str:
    """ç”Ÿæˆè¯„è®ºåˆ†æç« èŠ‚ - å±•ç¤ºè¯„è®ºçš„èˆ†æƒ…æƒ…å†µ"""
    comments_data = analysis.get("comments_analysis", {})
    
    total_comments = comments_data.get("total_comments", 0)
    comments_sentiment = comments_data.get("comments_sentiment", {})
    high_risk_comments = comments_data.get("high_risk_comments", [])
    
    if total_comments == 0:
        return """## ğŸ’¬ è¯„è®ºèˆ†æƒ…åˆ†æ

å½“å‰ç›‘æµ‹å†…å®¹æš‚æ— è¯„è®ºæ•°æ®ã€‚

---

"""
    
    # è®¡ç®—ç™¾åˆ†æ¯”
    total = sum(comments_sentiment.values())
    sentiment_pct = {
        label: int(count * 100 / total) if total > 0 else 0
        for label, count in comments_sentiment.items()
    }
    
    section = "## ğŸ’¬ è¯„è®ºèˆ†æƒ…åˆ†æ\n\n"
    
    # è¯„è®ºæ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ
    section += "### è¯„è®ºæ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ\n\n"
    section += f"**æ€»è¯„è®ºæ•°**ï¼š{total_comments} æ¡\n\n"
    
    section += "| æƒ…æ„Ÿ | æ•°é‡ | å æ¯” |\n"
    section += "|------|------|------|\n"
    
    for sentiment in ["positive", "neutral", "negative"]:
        emoji = get_sentiment_emoji(sentiment)
        label_cn = {"positive": "æ­£é¢", "neutral": "ä¸­æ€§", "negative": "è´Ÿé¢"}[sentiment]
        count = comments_sentiment.get(sentiment, 0)
        pct = sentiment_pct.get(sentiment, 0)
        section += f"| {emoji} {label_cn} | {count} | {pct}% |\n"
    
    section += "\n---\n\n"
    
    # é«˜é£é™©è¯„è®º
    if high_risk_comments:
        section += f"### âš ï¸ é«˜é£é™©è¯„è®ºï¼ˆå…± {len(high_risk_comments)} æ¡ï¼‰\n\n"
        
        for i, comment in enumerate(high_risk_comments[:10], 1):
            section += f"**è¯„è®º {i}**\n\n"
            section += f"- ğŸ“ å†…å®¹ï¼š{comment['content'][:150]}{'...' if len(comment['content']) > 150 else ''}\n"
            section += f"- ğŸ‘¤ è¯„è®ºäººï¼š{comment['author']}\n"
            section += f"- ğŸ”‘ é£é™©å…³é”®è¯ï¼š{', '.join(comment['keywords'][:3])}\n"
            if comment.get('engagement', 0) > 0:
                section += f"- ğŸ‘ è·èµæ•°ï¼š{comment['engagement']}\n"
            section += "\n"
        
        if len(high_risk_comments) > 10:
            section += f"*â€¦è¿˜æœ‰ {len(high_risk_comments) - 10} æ¡é«˜é£é™©è¯„è®ºæœªå±•ç¤º*\n\n"
        
        section += "---\n\n"
    else:
        section += "### âœ… æ­£é¢è¯„è®ºå¤šã€é£é™©è¯„è®ºå°‘\n\n"
        section += f"åœ¨ {total_comments} æ¡è¯„è®ºä¸­ï¼Œæœªå‘ç°åŒ…å«é£é™©å…³é”®è¯çš„é«˜é£é™©è¯„è®ºã€‚\n\n"
        section += "---\n\n"
    
    # è¯„è®ºå»ºè®®
    section += "### ğŸ’¡ è¯„è®ºç®¡ç†å»ºè®®\n\n"
    
    negative_count = comments_sentiment.get("negative", 0)
    if negative_count > total * 0.1:  # è´Ÿé¢è¯„è®ºè¶…è¿‡10%
        section += f"- ğŸ¯ **é‡ç‚¹å…³æ³¨**ï¼šè´Ÿé¢è¯„è®ºå æ¯”{sentiment_pct['negative']}%ï¼Œå»ºè®®å¢åŠ æ­£é¢å›åº”\n"
    else:
        section += f"- âœ… **èˆ†æƒ…çŠ¶æ€**ï¼šè´Ÿé¢è¯„è®ºä»…å {sentiment_pct['negative']}%ï¼Œä¿æŒç›®å‰ç­–ç•¥\n"
    
    if high_risk_comments:
        section += f"- âš ï¸ **é£é™©é¢„è­¦**ï¼šå‘ç°{len(high_risk_comments)}æ¡é«˜é£é™©è¯„è®ºï¼Œéœ€è¦å°½å¿«å›åº”å¤„ç†\n"
    else:
        section += f"- ğŸ‘ **ç»§ç»­ä¿æŒ**ï¼šè¯„è®ºåŒºæ²¡æœ‰æ˜æ˜¾é£é™©å†…å®¹ï¼Œç»§ç»­ç»´æŒè‰¯å¥½äº’åŠ¨\n"
    
    positive_count = comments_sentiment.get("positive", 0)
    if positive_count > 0:
        section += f"- ğŸŒŸ **ç”¨æˆ·å€¡å¯¼**ï¼š{positive_count}æ¡æ­£é¢è¯„è®ºï¼Œå¯è€ƒè™‘å±•ç¤ºæˆ–è½¬å‘ï¼Œæ”¾å¤§æ­£é¢å£°éŸ³\n"
    
    section += "\n---\n\n"
    
    return section


def generate_report(analysis: Dict) -> str:
    """
    ç”Ÿæˆå®Œæ•´çš„ä¼˜åŒ–ç‰ˆæŠ¥å‘Š

    Args:
        analysis: å®Œæ•´çš„åˆ†æç»“æœ

    Returns:
        å®Œæ•´çš„markdownæŠ¥å‘Š
    """
    report_sections = [
        generate_executive_summary(analysis),
        generate_competitor_comparison(analysis),
        generate_sentiment_overview_v2(analysis),
        generate_platform_analysis(analysis),
        generate_risk_alerts(analysis),
        generate_negative_details(analysis),
        generate_trending_topics_v2(analysis),
        generate_comments_analysis(analysis),
        generate_account_monitoring(analysis),
        generate_recommendations(analysis),
        generate_appendix(analysis)
    ]

    return "".join(report_sections)



def generate_sentiment_overview_v2(analysis: Dict) -> str:
    """ç”Ÿæˆæƒ…æ„Ÿæ¦‚è§ˆ - ç®€åŒ–ç‰ˆ"""
    metrics = analysis["metrics"]
    sentiment_dist = metrics["sentiment_dist"]
    sentiment_pct = metrics["sentiment_pct"]

    overview = """## ğŸ“ˆ èˆ†æƒ…æ¦‚è§ˆ

### æ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒ

| æƒ…æ„Ÿ | æ•°é‡ | å æ¯” | ä»£è¡¨å†…å®¹ |
|------|------|------|----------|
"""

    # ä¸ºæ¯ç§æƒ…æ„Ÿæ‰¾ä¸€ä¸ªä»£è¡¨å†…å®¹
    all_items = analysis.get("all_items", [])

    for sentiment in ["positive", "neutral", "negative"]:
        label_cn = {"positive": "æ­£é¢", "neutral": "ä¸­æ€§", "negative": "è´Ÿé¢"}[sentiment]
        emoji = get_sentiment_emoji(sentiment)
        count = sentiment_dist.get(sentiment, 0)
        pct = sentiment_pct.get(sentiment, 0)

        # æ‰¾ä»£è¡¨å†…å®¹
        sample_item = next((item for item in all_items if item["sentiment"]["label"] == sentiment), None)
        if sample_item:
            title = sample_item["title"][:30] if sample_item["title"] else sample_item["content"][:30]
            url = sample_item.get("url", "")
            sample_link = f"[{title}...]({url})" if url else f"{title}..."
        else:
            sample_link = "-"

        overview += f"| {emoji} {label_cn} | {count} | {pct}% | {sample_link} |\n"

    overview += "\n---\n\n"
    return overview


def generate_trending_topics_v2(analysis: Dict) -> str:
    """ç”Ÿæˆçƒ­ç‚¹è¯é¢˜ - ç®€åŒ–ç‰ˆ"""
    topics = analysis.get("topics", [])

    if not topics:
        return """## ğŸ”¥ çƒ­ç‚¹è¯é¢˜

å½“å‰æš‚æ— æ˜æ˜¾çƒ­ç‚¹è¯é¢˜ã€‚

---

"""

    section = "## ğŸ”¥ çƒ­ç‚¹è¯é¢˜\n\n"
    section += "### Top 5 çƒ­é—¨è¯é¢˜\n\n"

    for i, topic in enumerate(topics[:5], 1):
        sentiment_dist = topic["sentiment_dist"]

        section += f"**{i}. #{topic['topic']}** ({topic['count']} æ¬¡æåŠ)\n\n"
        section += f"- å¹³å‡äº’åŠ¨ï¼š{format_number(int(topic['avg_engagement']))}\n"
        section += f"- ä¸»è¦æƒ…æ„Ÿï¼š{get_sentiment_emoji(topic['sentiment'])} {topic['sentiment']}\n"

        # æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_breakdown = ", ".join([
            f"{label} {count}"
            for label, count in sentiment_dist.items()
        ])
        section += f"- æƒ…æ„Ÿåˆ†å¸ƒï¼š{sentiment_breakdown}\n\n"

    section += "---\n\n"
    return section


if __name__ == "__main__":
    # æµ‹è¯•
    print("Report Generator V2 - Optimized")
    print("=" * 70)
    print("âœ… Module loaded successfully")
